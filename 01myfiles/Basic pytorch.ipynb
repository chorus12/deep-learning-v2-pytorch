{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic pytorch stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jupytext] Reading Basic pytorch.ipynb\n",
      "[jupytext] Writing Basic pytorch.md (destination file replaced)\n"
     ]
    }
   ],
   "source": [
    "!jupytext --to markdown \"Basic pytorch.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a 3d tensor \n",
    "pay attention that torch.int = int32 and simple int = int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6]],\n",
      "\n",
      "        [[1, 2, 3],\n",
      "         [4, 5, 6]],\n",
      "\n",
      "        [[1, 2, 3],\n",
      "         [4, 5, 6]]], dtype=torch.int32) \n",
      "\n",
      " torch.Size([3, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "y = torch.tensor([\n",
    "     [[1, 2, 3],\n",
    "      [4, 5, 6]],\n",
    "     [[1, 2, 3],\n",
    "      [4, 5, 6]],\n",
    "     [[1, 2, 3],\n",
    "      [4, 5, 6]]], \n",
    "    dtype = torch.int)\n",
    "print(y, \"\\n\\n\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making summation over different dimentions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3,  6,  9],\n",
       "        [12, 15, 18]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5, 7, 9],\n",
       "        [5, 7, 9],\n",
       "        [5, 7, 9]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6, 15],\n",
       "        [ 6, 15],\n",
       "        [ 6, 15]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.sum(dim=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Float tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.6011e-38, 4.5866e-41, 1.3215e-12],\n",
      "        [3.0663e-41, 1.4013e-45, 4.5866e-41]]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor(2,3)\n",
    "print(x, x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.68070255, 0.61317935, 0.75916742],\n",
       "       [0.14941783, 0.34229245, 0.91174874]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_array = np.random.random((2,3)).astype(float)\n",
    "np_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6807, 0.6132, 0.7592],\n",
      "        [0.1494, 0.3423, 0.9117]]) torch.float32 \n",
      "\n",
      " tensor([[-0.9780,  0.0616, -0.0514],\n",
      "        [ 1.3100,  0.6309,  0.2642]]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.FloatTensor(np_array)\n",
    "x2 = torch.randn(2,3)\n",
    "print(x1, x1.dtype, \"\\n\\n\",x2, x2.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integer tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3], dtype=torch.int32), torch.int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_tensor = torch.arange(4, dtype=torch.int)\n",
    "int_tensor, int_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 3]], dtype=torch.int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_tensor.view(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(63, dtype=torch.int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(y, dtype=torch.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000,  2.7183,  7.3891, 20.0855])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = torch.exp(int_tensor.float())\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  2.7183, 14.7781, 60.2566])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_tensor*e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matmul and MM plus devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6670,  1.4792],\n",
       "        [-0.1720,  0.6526]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(x1, x2.t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6670,  1.4792],\n",
       "        [-0.1720,  0.6526]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(x1, x2.t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.66702986,  1.4791664 ],\n",
       "       [-0.1719538 ,  0.6526077 ]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(x1.numpy(), x2.t().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6670,  1.4792],\n",
       "        [-0.1720,  0.6526]], dtype=torch.float64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(x1.to(torch.float64), x2.to(torch.float64).t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device=torch.device('cuda')\n",
    "x1 = x1.to(device)\n",
    "x1.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3395,  0.7248],\n",
       "        [-1.6600, -0.0285],\n",
       "        [-0.3693, -1.8319]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3,2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can't convert CUDA tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    x.to(device).numpy()\n",
    "except RuntimeError as e:\n",
    "    print(e)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "finally:\n",
    "    print('OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-248-9868ff2c1551>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "torch.mm(torch.ones(2,3), torch.ones(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 3.])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(torch.ones(2,3), torch.ones(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A bit of autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3.], requires_grad=True)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(0,4).float().requires_grad_(True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 4., 6.])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.nn.Linear(4,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=4, out_features=2, bias=True)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3.])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = torch.arange(0,4).float()\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = net(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.6486, -0.9467], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0062, -0.0700,  0.2314, -0.3623],\n",
      "        [ 0.2912, -0.1247, -0.1449, -0.1122]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0457, -0.1956], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in net.parameters():\n",
    "    print (param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Простейшие перцептрончики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(torch.nn.Module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.layer1 = torch.nn.Linear(input_size, hidden_size)\n",
    "        self.layer2 = torch.nn.Linear(hidden_size,2)\n",
    "        self.layer3 = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input_val):\n",
    "        h = input_val\n",
    "        h = self.layer1(h)\n",
    "        h = self.layer2(h)\n",
    "        h = self.layer3(h)\n",
    "        return h\n",
    "    \n",
    "    def print_params(self):\n",
    "        for item in self.named_parameters():\n",
    "            print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MyNet(4,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('layer1.weight', Parameter containing:\n",
      "tensor([[-0.1583,  0.3567,  0.3486, -0.0454],\n",
      "        [-0.0739,  0.4934, -0.2603,  0.0862],\n",
      "        [-0.0727, -0.4693,  0.3118, -0.2353],\n",
      "        [-0.2766,  0.3744,  0.2552,  0.1936],\n",
      "        [ 0.2989,  0.1068,  0.3625,  0.1305],\n",
      "        [ 0.1892, -0.4528,  0.0262, -0.0850],\n",
      "        [-0.2442,  0.0044, -0.3989, -0.0772],\n",
      "        [-0.1609,  0.3161, -0.1666,  0.4822],\n",
      "        [-0.0036, -0.3015,  0.3174,  0.2475],\n",
      "        [-0.1829,  0.3347, -0.4266,  0.3965],\n",
      "        [-0.0856,  0.3709,  0.2133, -0.2934],\n",
      "        [ 0.2672,  0.4092,  0.0927,  0.3500],\n",
      "        [ 0.0573,  0.2821,  0.2022, -0.0999],\n",
      "        [ 0.4962,  0.2974,  0.2953, -0.0262],\n",
      "        [-0.1438,  0.3702,  0.4619,  0.2413],\n",
      "        [ 0.3241,  0.2545,  0.3146,  0.3213]], requires_grad=True))\n",
      "('layer1.bias', Parameter containing:\n",
      "tensor([-0.0095, -0.1366,  0.1833, -0.4231, -0.1795,  0.3327, -0.1543,  0.3713,\n",
      "         0.3201,  0.3860, -0.4400, -0.3983, -0.3827,  0.2750, -0.4396,  0.0322],\n",
      "       requires_grad=True))\n",
      "('layer2.weight', Parameter containing:\n",
      "tensor([[-0.0078, -0.0207, -0.0325,  0.1505, -0.0515,  0.0540, -0.0139,  0.2209,\n",
      "          0.0886,  0.1080,  0.0639,  0.1215,  0.0174, -0.0437, -0.2463, -0.1064],\n",
      "        [ 0.0767, -0.0497,  0.2114,  0.1676, -0.1738, -0.1437, -0.0812,  0.0552,\n",
      "          0.1724,  0.2135, -0.0618, -0.1620, -0.1215, -0.1518,  0.2316,  0.0105]],\n",
      "       requires_grad=True))\n",
      "('layer2.bias', Parameter containing:\n",
      "tensor([ 0.0942, -0.2185], requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "net.print_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5246, 0.5869], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.forward(torch.rand(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNet2(torch.nn.Sequential):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__(nn.Linear(input_size, hidden_size), \n",
    "                         nn.Linear(hidden_size, output_size), \n",
    "                         nn.Softmax(dim=1))\n",
    "    def print_params(self):\n",
    "        for item in self.parameters():\n",
    "            print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_net2(input_size, hidden_size, output_size):\n",
    "    return nn.Sequential(nn.Linear(input_size, hidden_size), \n",
    "                             nn.Linear(hidden_size, output_size), \n",
    "                             nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttt = MyNet2(4,16, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = make_net2(4,16,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3793, 0.3303, 0.5239, 0.6062, 0.5702, 0.4860, 0.6190, 0.5291, 0.4958,\n",
       "        0.3813], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.forward(torch.ones(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=4, out_features=16, bias=True)\n",
       "  (1): Linear(in_features=16, out_features=10, bias=True)\n",
       "  (2): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0401, 0.0630, 0.1632, 0.1117, 0.1190, 0.0536, 0.0935, 0.0718, 0.1397,\n",
       "         0.1445]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttt.forward(torch.ones(1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3135)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = torch.full([10, 64], 0.999)  # A prediction (logit)\n",
    "pos_weight = torch.ones([64])  # All weights are equal to 1\n",
    "criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "criterion(output, target)  # -log(sigmoid(0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Experimenting with convolutions and autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make an input tensor that does not require grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 2., 3.],\n",
       "          [4., 5., 6.],\n",
       "          [7., 8., 9.]]]])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is an input tensor\n",
    "input_tensor = torch.arange(1,10).to(torch.float).view((1,1,3,3))\n",
    "input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tenosr does not require a grad wrt it: False\n"
     ]
    }
   ],
   "source": [
    "print(f\"The tenosr does not require a grad wrt it: {input_tensor.requires_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make a custom conv2d layer that initializes all weights to 1 and does not have a bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2dCustom(nn.Conv2d):\n",
    "    def __init__(self, in_channels=1, out_channels=1, kernel_size=(3,3)):\n",
    "        super().__init__(in_channels, out_channels, kernel_size, bias=False)\n",
    "        self.weight.data = torch.ones((in_channels, out_channels, *kernel_size))\n",
    "        #self.bias.data = torch.zeros(1)\n",
    "    def __repr__(self):\n",
    "        super_repr =  super().__repr__()\n",
    "        return super_repr+'\\nweights:\\n'+str(self.weight.data)#+'\\nbias:\\n'+str(self.bias.data)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2dCustom(1, 1, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "weights:\n",
       "tensor([[[[1., 1., 1.],\n",
       "          [1., 1., 1.],\n",
       "          [1., 1., 1.]]]])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_conv2d = Conv2dCustom()\n",
    "layer_conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "See if conv 2d requires grad: True\n"
     ]
    }
   ],
   "source": [
    "print(f'See if conv 2d requires grad: {layer_conv2d.weight.requires_grad}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provided all weights of a convolution are 1 - this assert should be correct\n",
    "assert layer_conv2d(input_tensor) == input_tensor.sum().item() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no gradient so far\n",
    "type(layer_conv2d.weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.0"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor.sum().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that Linear layers can be replaced with convolutions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[45.]]]], grad_fn=<ThnnConv2DBackward>)\n"
     ]
    }
   ],
   "source": [
    "# and now let's coumpute the output of a single conv layer and run backward grad propagation\n",
    "input_tensor.requires_grad_()\n",
    "out = layer_conv2d(input_tensor)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 2., 3.],\n",
       "          [4., 5., 6.],\n",
       "          [7., 8., 9.]]]], requires_grad=True)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient w.r.t. input tensor (equals to weights of convolution)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 1., 1.],\n",
       "          [1., 1., 1.],\n",
       "          [1., 1., 1.]]]])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Gradient w.r.t. input tensor (equals to weights of convolution)')\n",
    "input_tensor.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[1., 1., 1.],\n",
       "          [1., 1., 1.],\n",
       "          [1., 1., 1.]]]], requires_grad=True)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_conv2d.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient w.r.t convolution weight (equals to input tensor)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 2., 3.],\n",
       "          [4., 5., 6.],\n",
       "          [7., 8., 9.]]]])"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Gradient w.r.t convolution weight (equals to input tensor)')\n",
    "layer_conv2d.weight.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we see here is that multiplication is a **gradient switcher**, i.e. gradient **w.r.t  x=w** and grad w.r.t **w** equals to **x**\n",
    "$$\n",
    "\\large Out = \\sum_i^n{w_i * x_i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight Parameter containing:\n",
      "tensor([[[[-0.0692, -0.2108, -0.3296],\n",
      "          [-0.2549,  0.0373,  0.1311],\n",
      "          [ 0.3123, -0.0539,  0.0950]]]], requires_grad=True) torch.Size([1, 1, 3, 3])\n",
      "bias Parameter containing:\n",
      "tensor([0.1419], requires_grad=True) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "conv2d_filter = nn.Conv2d(1,1,(3,3))\n",
    "for param, data in conv2d_filter.named_parameters():\n",
    "    print(param, data, data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D Convolutions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weight(m):\n",
    "    from functools import reduce\n",
    "    l = reduce(lambda x,y: x*y, m.weight.data.shape)\n",
    "    if type(m) == nn.Conv1d:\n",
    "        m.weight.data = torch.arange(l).to(torch.float).reshape(m.weight.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv1d(1, 3, kernel_size=(3,), stride=(1,), bias=False)"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_conv1d = nn.Conv1d(in_channels=1, out_channels=3, kernel_size=3, bias=False)\n",
    "layer_conv1d.apply(init_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 1., 2.]],\n",
       "\n",
       "        [[3., 4., 5.]],\n",
       "\n",
       "        [[6., 7., 8.]]])"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_conv1d.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_conv1d.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.,  1.,  2.,  3.]],\n",
       "\n",
       "        [[ 4.,  5.,  6.,  7.]],\n",
       "\n",
       "        [[ 8.,  9., 10., 11.]]])"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_1d_input = torch.arange(12).to(torch.float).view(3,1,4)\n",
    "conv_1d_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra = torch.FloatTensor([[[ 0.,  1.,  2.,  3.]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_1d_input = torch.cat((conv_1d_input, extra), dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.,  1.,  2.,  3.]],\n",
       "\n",
       "        [[ 4.,  5.,  6.,  7.]],\n",
       "\n",
       "        [[ 8.,  9., 10., 11.]],\n",
       "\n",
       "        [[ 0.,  1.,  2.,  3.]]])"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_1d_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2., 3.]])"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_1d_input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_1d_out = layer_conv1d(conv_1d_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  5.,   8.],\n",
       "         [ 14.,  26.],\n",
       "         [ 23.,  44.]],\n",
       "\n",
       "        [[ 17.,  20.],\n",
       "         [ 62.,  74.],\n",
       "         [107., 128.]],\n",
       "\n",
       "        [[ 29.,  32.],\n",
       "         [110., 122.],\n",
       "         [191., 212.]],\n",
       "\n",
       "        [[  5.,   8.],\n",
       "         [ 14.,  26.],\n",
       "         [ 23.,  44.]]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_1d_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.,  8.],\n",
       "        [14., 26.],\n",
       "        [23., 44.]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_1d_out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
